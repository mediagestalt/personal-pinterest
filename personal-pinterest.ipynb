{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinterest Image Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is some scraping code that downloads images from Pinterest, with the help of another tool called <a href=\"http://www.pinback.it/\" target=\"_blank\">`Pinback`</a>. Pinback creates a bookmark file with all of the image URL's from your Pinterest collection. This code scrapes the bookmark file and downloads all of the images to a local file on your computer, using part of the image URL for a unique file name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://pypi.python.org/pypi/beautifulsoup4\" target=\"_blank\">`Beautiful Soup`</a> is a web scraping module that needs to be downloaded first. I generally install with <a href=\"https://pip.pypa.io/en/stable/installing/\">`pip`</a>, but that's up to you. `urllib` is a pre-installed module. You'll also need to install <a href=\"http://lxml.de/installation.html\" target=\"_blank\">`lxml`</a>, which is needed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saved all the `html` files that I downloaded from Pinback into one folder. This created one file for each notebook I had in Pinterest. I wanted to keep the photos separate from each notebook, so I wrote this code to do one file at a time. You could write a loop here to iterate through several different files at once if you needed that.\n",
    "\n",
    "This code also calls the Beautiful soup function to parse the file. You must use the `lxml` operator here; it is necessary because of the file encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = open('path/to/saved/Pinback/file.html')\n",
    "soup = BeautifulSoup(r, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is commented out, but this will print a snippet of the file if you feel like taking a look at the structure. This might be helpful if you want to scrape more info out of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (soup.prettify())[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image URLs come directly via a Pinterest URL, and not from the original image source. This is where you might want to scrape more info from the other attributes in the `<a>` tag, after looking at the above printout of the file.\n",
    "\n",
    "Yes, there are issues with copyright here, and in all honesty, Pinterest doesn't do a good job of helping users with attribution. Just know that all of the images (unless created by you) are subject to the copyright laws in your country, for use at your own risk. My personal motto is: <a href=\"https://www.akpress.org/youdonthavetofuckpeopleover.html\" target=\"_blank\">`You don't have to fuck people over to survive`</a>, so try and give credit where credit is due. A good first approach (if you want to use the image for a non-personal use) would be conducting a <a href=\"https://images.google.ca/\" target=\"_blank\">`reverse image search`</a> to find the owner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create empty list\n",
    "img_link=[]\n",
    "# finds each unique entry\n",
    "for link in soup.find_all('a'): \n",
    "    # locates the attribute 'image' and appends the link to the list\n",
    "    img_link.append(link.get('image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterates through list\n",
    "for img in img_link:\n",
    "    # creates a filename from the URL by spliting it on the last '/'\n",
    "    file_name = img.split('/')[-1]\n",
    "    # this is the scraper: it downloads the file and saves it in the current folder\n",
    "    urllib.request.urlretrieve(img, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
